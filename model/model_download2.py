# -*- coding: utf-8 -*-
"""Một bản sao khác của Main Datathon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O6PMoskExRx__aryJyRwN36wIUF71nd8

# Load the data
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install -U fashion-clip

import sys
# sys.path.append("fashion-clip/")
from fashion_clip.fashion_clip import FashionCLIP
import pandas as pd
import numpy as np
from collections import Counter
from PIL import Image
import requests
from io import BytesIO
import zipfile

# Commented out IPython magic to ensure Python compatibility.
# %%capture
fclip = FashionCLIP('fashion-clip')

# Link to the zip file
url = "https://drive.google.com/file/d/1Y-CseR1n75De_eCN9aCVEIRlqY_MmqjP/view"

# Extract the file ID from the link
file_id = url.split("/")[-2]

# Create the download link
download_link = f"https://drive.google.com/uc?id={file_id}"

# Download the content of the zip file
response = requests.get(download_link)
zip_data = BytesIO(response.content)

# Unzip the file
with zipfile.ZipFile(zip_data, 'r') as zip_ref:
    # Get the list of files in the zip
    file_list = zip_ref.namelist()

    # Choose the Excel file from the list (assuming only one Excel file)
    excel_file = [file for file in file_list if file.endswith('.xlsx')][0]

    # Read data from the Excel file using pandas
    df = pd.read_excel(zip_ref.open(excel_file))

df.head()

df.shape

df.columns

df.rename(columns={'Unnamed: 0': 'ID'}, inplace=True)

# Concatenate 'description' and 'color' columns with a separator
df['description'] = 'Color of product: ' + df['color'].astype(str) + '. ' + df['description']

# Drop the specified columns from the DataFrame
df = df.drop(columns=['price', 'review_count', 'avg_rating', 'scraped_at', 'color', 'brand', 'currency', 'availability'])

df = df.dropna(subset=['images', 'description', 'name'])

df = df.drop_duplicates()

df = df.reset_index(drop=True)

df.isnull().sum()

check_duplicates = lambda df: df[df.duplicated()]

duplicates = check_duplicates(df)

if duplicates.empty:
    print("No duplicates found.")
else:
    print("Duplicates in:")
    print(duplicates)

df.head(5)

"""## Text preprocessing"""

df['description'].iloc[0]

import re
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
from nltk.tokenize import sent_tokenize, word_tokenize

nltk.download('punkt')
nltk.download('wordnet')
nltk.download('stopwords')

con_appos = {
    "rep": "represent",
    "hoodie": "hooded sweatshirt",
    "tee": "t-shirt",
    "zip": "zip-up",
    "maxi": "maxi dress",
    "mini": "mini dress",
    "midi": "midi dress",
    "denim": "denim fabric",
    "chino": "chino pants",
    "cropped": "cropped length",
    "floral": "floral print",
    "striped": "striped pattern",
    "polka": "polka dot",
    "v-neck": "v-neckline",
    "crew-neck": "crew neckline",
    "slim": "slim fit",
    "loose": "loose fit",
    "bootcut": "bootcut style",
    "skinny": "skinny fit",
    "isn't": "is not",
    "it'd": "it would",
    "it'd've": "it would have",
    "it'll": "it will",
    "it'll've": "it will have",
    "it's": "it is",
    "mayn't": "may not",
    "might've": "might have",
    "mightn't": "might not",
    "mightn't've": "might not have",
    "must've": "must have",
    "mustn't": "must not",
    "mustn't've": "must not have",
    "needn't": "need not",
    "needn't've": "need not have",
    "so've": "so have",
    "so's": "so is",
    "that'd": "that would",
    "that'd've": "that would have",
    "that's": "that is",
    "there'd": "there would",
    "there'd've": "there would have",
    "there's": "there is",
    "they'd": "they would",
    "they'd've": "they would have",
    "they'll": "they will",
    "they'll've": "they will have",
    "they're": "they are",
    "they've": "they have",
    "we're": "we are",
    "to've": "to have"
}

def preprocessed_description(text):
    # Ensure the input text is a string
    text = str(text)

    # Convert the text to lowercase
    text = text.lower()

    # Change abbreviated words into full words
    pattern = re.compile(r'\b(' + r'|'.join(con_appos.keys()) + r')\b')
    text = pattern.sub(lambda x: con_appos[x.group()], text)

    # Remove special characters and numbers
    text = re.sub(r'\W', ' ', text)
    text = re.sub(r'\d+', ' ', text)

    # Remove html tags
    Tag_re = re.compile(r'<[^>]+>')
    text  = Tag_re.sub(' ', text)

    # Remove multiple spaces
    text = re.sub(r'\s+', ' ', text)

    # Remove stopwords
    stopwords_list = [word for word in stopwords.words('english') if word != 'not']
    pattern = re.compile(r'\b(' + r'|'.join(stopwords_list) + r')\b\s*')
    text = pattern.sub('', text)

    # Lemmatize words
    lemmatizer = WordNetLemmatizer()
    text = ' '.join(lemmatizer.lemmatize(word) for word in nltk.word_tokenize(text))

    return text

# Apply preprocessing to the 'description' column
df['description'] = df['description'].apply(preprocessed_description)

df['description'].iloc[0]

"""## Images preprocessing"""

df['images'].loc[0]

import ast

def convert_to_list(link_str):
    try:
        # Check if the link_str contains "~" delimiter
        if "~" in link_str:
            link_list = link_str.split("~")
        else:
            # Convert the string representation of a list to an actual list
            link_list = ast.literal_eval(link_str)

        # Strip whitespaces around each link
        return [link.strip() for link in link_list]
    except (SyntaxError, ValueError):
        print(f"Error converting {link_str} to a list")
        return None

df['images'] = df['images'].apply(lambda x: convert_to_list(x))

df = df.dropna(subset=['images']).reset_index(drop=True)

def filter_invalid_urls(image_urls):
    # Filter out URLs that are base64-encoded images
    valid_urls = [url for url in image_urls if 'data:image' not in url]
    return valid_urls

# Example usage:
df['images'] = df['images'].apply(filter_invalid_urls)

import concurrent.futures
import requests

def is_valid_url(url):
    try:
        # Check if the URL starts with a valid protocol
        if url.startswith(('http://', 'https://')):
            # Check if the URL is reachable (status code 200)
            response = requests.head(url, timeout=5)  # Set a timeout to avoid long waits
            return response.status_code == 200
        else:
            print(f"Invalid URL format: {url}")
            return False
    except requests.RequestException as e:
        print(f"Error checking {url}: {e}")
        return False

def filter_valid_urls(image_urls):
    valid_urls = []

    # Iterate through each URL in the list
    for url in image_urls:
        # Check if the URL is valid
        if is_valid_url(url):
            # Add the valid URL to the list and break the loop
            valid_urls.append(url)
            break

    return valid_urls

# Example usage:
df['images'] = df['images'].apply(filter_valid_urls)

df['images'].iloc[2144]

# Save the preprocessed DataFrame to a pickle file
df.to_pickle('preprocessed_data.pkl')

"""# FashionCLIP pre-trained model"""

image_urls_list = df['images'].tolist()
images = []

# Iterate over each item in the image_urls_list and convert image URLs to a list
for image_urls in image_urls_list:
    images.extend(image_urls)

texts = df['description'].tolist()

# we create image embeddings and text embeddings
image_embeddings = fclip.encode_images(images, batch_size=32)
text_embeddings = fclip.encode_text(texts, batch_size=32)

# we normalize the embeddings to unit norm (so that we can use dot product instead of cosine similarity to do comparisons)
image_embeddings = image_embeddings / np.linalg.norm(image_embeddings, ord=2, axis=-1, keepdims=True)
text_embeddings = text_embeddings / np.linalg.norm(text_embeddings, ord=2, axis=-1, keepdims=True)

precision = 0

# we could batch this operation to make it faster
for index, t in enumerate(text_embeddings):
    arr = t.dot(image_embeddings.T)

    best = arr.argsort()[-15:][::-1]

    if index in best:
        precision += 1

precision_value = round(precision / len(text_embeddings), 2)
precision_value

text_embedding = fclip.encode_text(["shoes"], batch_size=32)[0]

# Compute similarity scores between text embedding and image embeddings
similarity_scores = np.dot(text_embedding, image_embeddings.T)

# Sort the images based on similarity scores in descending order
sorted_indices = np.argsort(similarity_scores)[::-1]

# Retrieve the top K most similar image URLs
top_k = 15  # Number of top similar images to retrieve
top_similar_image_urls = [images[i] for i in sorted_indices[:top_k]]

top_similar_image_urls

import matplotlib.pyplot as plt

def get_top_similar_images(text):
    # Encode text to get text embedding
    text_embedding = fclip.encode_text([text], batch_size=32)[0]

    # Compute similarity scores between text embedding and image embeddings
    similarity_scores = np.dot(text_embedding, image_embeddings.T)

    # Sort the images based on similarity scores in descending order
    sorted_indices = np.argsort(similarity_scores)[::-1]

    # Retrieve the top K most similar image URLs
    top_k = 5  # Number of top similar images to retrieve
    top_similar_image_urls = [images[i] for i in sorted_indices[:top_k]]

    # Create a dictionary with URLs and their corresponding similarity scores
    top_similar_images_info = [{'url': url, 'similarity_score': similarity_scores[i]} for i, url in enumerate(top_similar_image_urls)]

    # Plot the top 5 similar images
    fig, axes = plt.subplots(1, top_k, figsize=(15, 5))

    for i, image_url in enumerate(top_similar_image_urls):
        response = requests.get(image_url)
        image = Image.open(BytesIO(response.content))

        axes[i].imshow(image)
        axes[i].axis('off')
        axes[i].set_title(f"Score: {similarity_scores[sorted_indices[i]]:.2f}")

    plt.show()

    # Return the top similar image URLs along with their similarity scores
    return top_similar_images_info

get_top_similar_images("winter outfit for woman")

# Create a new DataFrame containing information of products in top_similar_image_urls
df_top_similar = df[df['images'].apply(lambda x: any(link in x for link in top_similar_image_urls))]

# Get the URL and name information of products in top_similar_image_urls
result_urls = df_top_similar['url'].tolist()
result_names = df_top_similar['name'].tolist()

# Display the results
for url, name in zip(result_urls, result_names):
    print(f"Name: {name}\n URL: {url}")

from transformers import ViTImageProcessor, ViTForImageClassification
from PIL import Image
import requests

# Tải mô hình
processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')

# Danh sách các nhãn lớp
labels = model.config.id2label

# Tạo từ điển để theo dõi các nhãn lớp và đường dẫn ảnh
class_dict = {}

# Dự đoán và phân loại từng hình ảnh
for image_url in top_similar_image_urls:
    # Tải ảnh từ URL
    response = requests.get(image_url, stream=True)
    response.raise_for_status()
    image = Image.open(response.raw)

    # Chuyển đổi hình ảnh thành RGB nếu chỉ có 2 chiều
    if image.mode != "RGB":
        image = image.convert("RGB")

    # Chuẩn bị dữ liệu đầu vào
    inputs = processor(images=image, return_tensors="pt")

    # Dự đoán nhãn lớp
    outputs = model(**inputs)
    predicted_class_index = outputs.logits.argmax(dim=1).item()
    predicted_label = labels[predicted_class_index]

    # Lưu trữ đường dẫn ảnh vào từ điển theo nhãn lớp
    if predicted_label not in class_dict:
        class_dict[predicted_label] = []
    class_dict[predicted_label].append(image_url)

# Hiển thị kết quả
for label, image_urls in class_dict.items():
    print(f'Label: {label}')
    print('Image URLs:')
    for image_url in image_urls:
        print(image_url)
    print('---')

# !pip install transformers --upgrade

from transformers import ViTImageProcessor, ViTForImageClassification
from PIL import Image
import requests
import numpy as np

# Tải mô hình
processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')
model = ViTForImageClassification.from_pretrained('google/vit-base-patch16-224')

# Danh sách các nhãn lớp
labels = model.config.id2label

# Tạo từ điển để theo dõi các nhãn lớp và đường dẫn ảnh
class_dict = {}

# Danh sách từ khóa cho phân loại
shirt_labels = ['belts', 'blazers', 'dresses', 'dupatta', 'jackets', 'kurtas', 'kurtis', 'lehenga choli', 'nehru jackets', 'rain jacket', 'bulletproof vest', 'cardigan',
       'rompers', 'shirts', 'shrug', 'suspenders', 'sweaters', 'sweatshirt', 'tops', 'T-shirt,', 'tunics', 'waistcoat', 'hoodie', 'jerrsey', 'tee shirt', 'maillot', 'fur coat'
       'wool', 'woolen', 'woollen', 'fur coat', 'brassiere', 'bra', 'bandeau', 'tank suit', 'brassiere', 'bandeau', 'sarong', 'pajama', 'pyjama', 'pj\'s', 'jammies', 'swimming trunks', 'bathing trunks'
       'bulletproof vest', 'maillot', 'tank suit', 'miniskirt', 'mini', 'sleeping bag', 'trench coat', 'lab coat', 'laboratory coat', 'velvet', 'fur coat']
pants_labels = ['capris', 'churidar', 'jeans', 'jeggings', 'leggings', 'patiala', 'salwar', 'salwar dupatta', 'shorts', 'skirts', 'stockings',
       'swimwear', 'tights', 'track pants', 'tracksuits', 'trousers', 'blue jean', 'jean', 'denim']
shoes_labels = ['casual shoes', 'flats', 'flip flops', 'formal shoes', 'heels', 'sandal'
       'sandals', 'sports sandals', 'sports shoes', 'boot', 'running shoe', 'hair slide', 'sabot']

# Dự đoán và phân loại từng hình ảnh
for image_url in top_similar_image_urls:
    # Tải ảnh từ URL
    image = Image.open(requests.get(image_url, stream=True).raw)

    # Chuyển đổi ảnh thành RGB nếu có một kênh duy nhất
    if image.mode != "RGB":
        image = image.convert("RGB")

    # Chuẩn bị dữ liệu đầu vào
    inputs = processor(images=np.array(image), return_tensors="pt")

    # Dự đoán nhãn lớp
    outputs = model(**inputs)
    predicted_class_index = outputs.logits.argmax(dim=1).item()
    predicted_label = labels[predicted_class_index]

    # Phân loại nhãn lớp thành "quần" (pants), "áo" (shirt), "giày" (shoes) hoặc "khác" (others)
    if any(label in predicted_label for label in pants_labels):
        predicted_label = "pants"
    elif any(label in predicted_label for label in shirt_labels):
        predicted_label = "shirt"
    elif any(label in predicted_label for label in shoes_labels):
        predicted_label = "shoes"
    else:
        predicted_label = "others"

    # Lưu trữ đường dẫn ảnh vào từ điển theo nhãn lớp
    if predicted_label not in class_dict:
        class_dict[predicted_label] = []
    class_dict[predicted_label].append(image_url)

# Hiển thị kết quả
for label, image_urls in class_dict.items():
    print(f'Label: {label}')
    print('Image URLs:')
    for image_url in image_urls:
        print(image_url)
    print('---')


import requests
from PIL import Image
from io import BytesIO
import matplotlib.pyplot as plt

def get_product_info(text):
    # Encode text to get text embedding
    text_embedding = fclip.encode_text([text], batch_size=32)[0]

    # Compute similarity scores between text embedding and image embeddings
    similarity_scores = np.dot(text_embedding, image_embeddings.T)

    # Sort the images based on similarity scores in descending order
    sorted_indices = np.argsort(similarity_scores)[::-1]

    # Retrieve the top K most similar image URLs
    top_k = 5  # Number of top similar images to retrieve
    top_similar_image_urls = [images[i] for i in sorted_indices[:top_k]]

    # Create a dictionary with URLs and their corresponding similarity scores
    top_similar_images_info = []

    for i, image_url in enumerate(top_similar_image_urls):
        response = requests.get(image_url)
        # image = Image.open(BytesIO(response.content))

        # Display the image
        # plt.imshow(image)
        # plt.axis('off')
        # plt.title(f"Score: {similarity_scores[sorted_indices[i]]:.2f}")
        # plt.show()

        # Append information to the result dictionary
        product_info = {
            'name': df[df['images'].apply(lambda x: image_url in x)]['name'].values[0],
            'image_url': image_url,
            'web_url': df[df['images'].apply(lambda x: image_url in x)]['url'].values[0]
        }

        top_similar_images_info.append(product_info)

    return top_similar_images_info

# Example usage:
text_input = "winter outfit"
result = get_product_info(text_input)

# Display the result
for item in result:
    print(f"Name: {item['name']}\nImage URL: {item['image_url']}\nWeb URL: {item['web_url']}\n")


import pickle

# Assume model là mô hình máy học của bạn đã được huấn luyện
# Ví dụ: Linear Regression

# Tạo mô hình

# Huấn luyện mô hình (giả sử đã huấn luyện)

# Lưu mô hình vào một file
with open('fclip_trainned.pkl', 'wb') as file:
    pickle.dump(fclip, file)